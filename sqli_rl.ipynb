{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATABASE CONFIGURATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.engine import URL\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import json\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'database': {'name': 'BikeStores', 'server': '.\\\\SQLEXPRESS', 'driver': 'SQL Server', 'sample_query': 'SELECT * FROM production.brands'}, 'rl': {'state_info': {'mark_error': True, 'query_result_length': 10000, 'padding_char': '\\x00'}, 'contexts': [{'query': 'SELECT * FROM production.products WHERE brand_id=8 [INPUT]', 'table_filter': ['production.products'], 'column_filter': ['product_name'], 'goal': 'Trek 820 - 2016'}]}}\n"
     ]
    }
   ],
   "source": [
    "with open('config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "    print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Up Connection to Microsoft SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   brand_id    brand_name\n",
      "0         1       Electra\n",
      "1         2          Haro\n",
      "2         3        Heller\n",
      "3         4   Pure Cycles\n",
      "4         5       Ritchey\n",
      "5         6       Strider\n",
      "6         7  Sun Bicycles\n",
      "7         8         Surly\n",
      "8         9          Trek\n"
     ]
    }
   ],
   "source": [
    "db = config['database']\n",
    "\n",
    "name = db['name']\n",
    "server = db['server']\n",
    "driver = db['driver']\n",
    "\n",
    "# Connect to SQL database using the above parameters.\n",
    "conn_string = f'DRIVER={driver};SERVER={server};DATABASE={name};Trusted_Connection=yes'\n",
    "conn_url = URL.create('mssql+pyodbc', query={'odbc_connect': conn_string})\n",
    "engine = create_engine(conn_url)\n",
    "\n",
    "# Display a dataframe from a sample query if set.\n",
    "if 'sample_query' in db:\n",
    "    sample_query = db['sample_query']\n",
    "    df = pd.read_sql(sample_query, engine)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REINFORCEMENT LEARNING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_info = config['rl']['state_info']\n",
    "mark_error = state_info['mark_error']\n",
    "query_result_length = state_info['query_result_length']\n",
    "padding_char = state_info['padding_char']\n",
    "\n",
    "# If a query result is an error, and if mark_error is true, this distinction will be added to the state information.\n",
    "# TODO: Ensure mark_error information has a higher weighting in the neural net.\n",
    "nn_input_size = query_result_length\n",
    "if(mark_error):\n",
    "    nn_input_size += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define RL Contexts and Incrementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not having any defined RL contexts will result in an error.\n",
    "contexts = config['rl']['contexts']\n",
    "context = contexts[0]\n",
    "context_index = 0\n",
    "\n",
    "# Increments RL context and returns whether another context was assigned.\n",
    "def incr_context():\n",
    "    global context, context_index\n",
    "    if context_index < len(contexts) - 1:\n",
    "        context_index += 1\n",
    "        context = contexts[context_index]\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 False\n"
     ]
    }
   ],
   "source": [
    "# TODO: Remove non-MSSQL payloads.\n",
    "payloads = open('sqli_payloads.txt', 'r').read().split('\\n')\n",
    "\n",
    "def inject_payload(payload_index):\n",
    "    payload = payloads[payload_index]\n",
    "    query = context['query']\n",
    "    query = query.replace('[INPUT]', payload)\n",
    "\n",
    "    try:\n",
    "        df = pd.read_sql(query, engine)\n",
    "        res = df.to_csv()\n",
    "        has_error = False\n",
    "    except:\n",
    "        res = str(sys.exc_info()[1])\n",
    "        has_error = True\n",
    "\n",
    "    # Trim resulting string or pad it so that the length is equal to query_result_length.\n",
    "    if len(res) > query_result_length:\n",
    "        res = res[:query_result_length]\n",
    "    else:\n",
    "        res = res.ljust(query_result_length, padding_char)\n",
    "\n",
    "    if mark_error:\n",
    "        return res, has_error\n",
    "    return res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "844694dc4390c811ac8b4d2fcaa7d18288efc8c697b009159baa2dd36f994a81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
